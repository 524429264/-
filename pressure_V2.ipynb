{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/524429264/-/blob/master/pressure_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9zS7JGHbHOk",
        "outputId": "19a60f62-fe9f-4c23-bbc6-18f08b3c013f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wAk_bSgZ0lC",
        "outputId": "f9bebde4-02c0-49ca-8874-0fb21e03b3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/50\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 设置随机种子以确保可重复性\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 数据加载和预处理函数\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for sample in os.listdir(data_dir):\n",
        "        sample_dir = os.path.join(data_dir, sample)\n",
        "        if os.path.isdir(sample_dir):\n",
        "            sample_images = []\n",
        "            for i in range(1, 21):\n",
        "                img_path = os.path.join(sample_dir, f'image_{i}.jpg')\n",
        "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "                sample_images.append(img_array)\n",
        "            images.append(np.array(sample_images))\n",
        "\n",
        "            with open(os.path.join(sample_dir, 'label.txt'), 'r') as f:\n",
        "                label = float(f.read().strip())\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# 数据增强\n",
        "def augment_data(images, labels):\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for image_seq, label in zip(images, labels):\n",
        "        augmented_images.append(image_seq)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # 水平翻转\n",
        "        flipped_seq = np.flip(image_seq, axis=2)\n",
        "        augmented_images.append(flipped_seq)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # 随机亮度变化\n",
        "        brightness_seq = tf.image.random_brightness(image_seq, max_delta=0.2)\n",
        "        augmented_images.append(brightness_seq.numpy())\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "    return np.array(augmented_images), np.array(augmented_labels)\n",
        "\n",
        "# 构建改进的模型\n",
        "def build_model(input_shape):\n",
        "    base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=input_shape[1:])\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.TimeDistributed(base_model),\n",
        "        layers.GlobalAveragePooling3D(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Huber损失函数\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    abs_error = tf.abs(error)\n",
        "    quadratic = tf.minimum(abs_error, delta)\n",
        "    linear = abs_error - quadratic\n",
        "    return 0.5 * tf.square(quadratic) + delta * linear\n",
        "\n",
        "# 学习率调度\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 10:\n",
        "        lr *= 0.1\n",
        "    return lr\n",
        "\n",
        "# 主函数\n",
        "def main():\n",
        "    # 加载数据\n",
        "    train_dir = 'drive/My Drive/explosion_data'\n",
        "    test_dir = 'drive/My Drive/explosion_testdata'\n",
        "\n",
        "    X_train, y_train = load_data(train_dir)\n",
        "    X_test, y_test = load_data(test_dir)\n",
        "\n",
        "    # 数据增强\n",
        "    X_train, y_train = augment_data(X_train, y_train)\n",
        "\n",
        "    # 数据标准化\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "\n",
        "    # K折交叉验证\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_no = 1\n",
        "    for train_index, val_index in kfold.split(X_train):\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        model = build_model(X_train.shape[1:])\n",
        "\n",
        "        optimizer = optimizers.Adam(learning_rate=1e-3)\n",
        "        model.compile(optimizer=optimizer, loss=huber_loss, metrics=['mae'])\n",
        "\n",
        "        lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            epochs=50,\n",
        "            batch_size=8,\n",
        "            callbacks=[lr_scheduler, early_stopping]\n",
        "        )\n",
        "\n",
        "        # 评估模型\n",
        "        test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "        print(f'Fold {fold_no} - Test MAE: {test_mae:.4f}')\n",
        "\n",
        "        # 预测测试集\n",
        "        y_pred = model.predict(X_test)\n",
        "        print(f'Fold {fold_no} - Predicted value: {y_pred[0][0]:.4f}, Actual value: {y_test[0]:.4f}')\n",
        "\n",
        "        fold_no += 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}